{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c552934",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4954ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylab import zeros, arange, subplots, plt, savefig\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import logging\n",
    "import torch\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c1dec6",
   "metadata": {},
   "source": [
    "#### Setup logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18640a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.addHandler(logging.StreamHandler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7bf2b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using torch: 1.4.0\n"
     ]
    }
   ],
   "source": [
    "logger.info(f'Using torch: {torch.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c48085f",
   "metadata": {},
   "source": [
    "#### Essentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85f052e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_ROOT = './data/'\n",
    "CAPTIONS_TRAIN_SET_PATH = 'embedding/caption_embedding.csv'\n",
    "CAPTIONS_VALIDATION_SET_PATH = 'embedding/caption_embedding.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df7c6a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIMENSIONALITY = 1000 # number of CNN outputs = dimensionality of the captions word2vec model\n",
    "BATCH_SIZE = 4 \n",
    "EPOCHS = 10\n",
    "WORKERS = 4 # number of data loading workers = CPU cores\n",
    "GPU = 0\n",
    "LR = 0.01 \n",
    "MOMENTUM = 0.9\n",
    "WEIGHT_DECAY = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83e290b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852077a1",
   "metadata": {},
   "source": [
    "#### Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c440df6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, embedding_dimensionality):\n",
    "        super(Model, self).__init__()\n",
    "        self.cnn = models.resnet50(pretrained=True, num_classes=embedding_dimensionality)\n",
    "\n",
    "    def forward(self, image):\n",
    "        x = self.cnn(image)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fea4c3",
   "metadata": {},
   "source": [
    "https://pytorch.org/docs/stable/generated/torch.nn.BCEWithLogitsLoss.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c50911a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.BCEWithLogitsLoss().cuda(GPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2cf059",
   "metadata": {},
   "source": [
    "Create ResNet50 model with custom number of outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "412c750f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(embedding_dimensionality=EMBEDDING_DIMENSIONALITY).cuda(GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca65edc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    eps: 1e-08\n",
       "    lr: 0.01\n",
       "    weight_decay: 0.0001\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46a86b1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): Model(\n",
       "    (cnn): ResNet(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "      (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.nn.DataParallel(model, device_ids=[GPU])\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af881e3d",
   "metadata": {},
   "source": [
    "#### Define and load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d5d12e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    def __init__(self, root_dir, split, embedding_dimensionality):\n",
    "        self.root_dir = root_dir\n",
    "        self.split = split\n",
    "        self.embedding_dimensionality = embedding_dimensionality\n",
    "        self.preprocess = transforms.Compose([transforms.RandomHorizontalFlip(), \n",
    "                                              transforms.RandomCrop(224), \n",
    "                                              transforms.ToTensor(), \n",
    "                                              transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                                                                   std=[0.229, 0.224, 0.225])])\n",
    "        logger.info(f'Loading data from {split}')\n",
    "        \n",
    "        # count number of images in the split\n",
    "        n = 0\n",
    "        with open(f'{DATASET_ROOT}{CAPTIONS_TRAIN_SET_PATH}', 'r') as f:\n",
    "            for _, _ in enumerate(f):\n",
    "                n += 1\n",
    "                \n",
    "        # placeholder for image ids - dummy bytes\n",
    "        self.img_ids = np.empty([n], dtype='S50')\n",
    "        # placeholder for captions embedding - [number of captions * vector dimension]\n",
    "        self.captions_embeddings = np.zeros((n, self.embedding_dimensionality), dtype=np.float32)\n",
    "        \n",
    "        # populate the placeholders \n",
    "        with open(f'{DATASET_ROOT}{CAPTIONS_TRAIN_SET_PATH}', 'r') as f:\n",
    "            for idx, row in enumerate(f):\n",
    "                uid, vec = row.split('\\t')\n",
    "                vec = vec.strip().split(',')\n",
    "                self.img_ids[idx] = uid\n",
    "                for i in range(self.embedding_dimensionality):\n",
    "                    self.captions_embeddings[idx, i] = float(vec[i])\n",
    "        logger.info(f'Caption embedding shape = {self.captions_embeddings[0].shape}')\n",
    "        logger.info('Data loading done.')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.img_ids[idx].decode('utf-8')\n",
    "        img = Image.open(f'{DATASET_ROOT}images/{img_id}.jpg').convert('RGB')\n",
    "        img_tensor = self.preprocess(img)\n",
    "        target_tensor = torch.from_numpy(self.captions_embeddings[idx, :])\n",
    "        return img_id, img_tensor, target_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8cd33288",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data from embedding/caption_embedding.csv\n",
      "Caption embedding shape = (1000,)\n",
      "Data loading done.\n"
     ]
    }
   ],
   "source": [
    "train_dataset = Dataset(DATASET_ROOT, CAPTIONS_TRAIN_SET_PATH, EMBEDDING_DIMENSIONALITY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "239d00d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfbdb9c",
   "metadata": {},
   "source": [
    "Dataset object wraps - image id, image tensor and the caption embedding tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69f1eaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_id, image_tensor, caption_embedding_tensor = train_dataset[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a90f466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1489658491986857252'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df671769",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 224, 224])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c3477b5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caption_embedding_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c92f9732",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data from embedding/caption_embedding.csv\n",
      "Caption embedding shape = (1000,)\n",
      "Data loading done.\n"
     ]
    }
   ],
   "source": [
    "val_dataset = Dataset(DATASET_ROOT, CAPTIONS_VALIDATION_SET_PATH, EMBEDDING_DIMENSIONALITY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ba6712",
   "metadata": {},
   "source": [
    "`pin_memory` allows better transferring of samples to GPU memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eb863812",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, \n",
    "                                           batch_size=BATCH_SIZE, \n",
    "                                           shuffle=True, \n",
    "                                           num_workers=WORKERS, \n",
    "                                           pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c1af598a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset': <__main__.Dataset at 0x7f69a92cc278>,\n",
       " 'num_workers': 4,\n",
       " 'pin_memory': True,\n",
       " 'timeout': 0,\n",
       " 'worker_init_fn': None,\n",
       " '_DataLoader__multiprocessing_context': None,\n",
       " '_dataset_kind': 0,\n",
       " 'batch_size': 4,\n",
       " 'drop_last': False,\n",
       " 'sampler': <torch.utils.data.sampler.RandomSampler at 0x7f69ae382b38>,\n",
       " 'batch_sampler': <torch.utils.data.sampler.BatchSampler at 0x7f69ae382b70>,\n",
       " 'collate_fn': <function torch.utils.data._utils.collate.default_collate(batch)>,\n",
       " '_DataLoader__initialized': True,\n",
       " '_IterableDataset_len_called': None}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "be3259eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = torch.utils.data.DataLoader(val_dataset, \n",
    "                                         batch_size=BATCH_SIZE, \n",
    "                                         shuffle=True, \n",
    "                                         num_workers=WORKERS, \n",
    "                                         pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "76be78a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1490000502002419365', '1487617674748909132', '1489696141964320706', '1487747485463161463'] tensor([[[[ 0.7077,  0.9988,  0.8447,  ..., -0.0116,  0.0227,  0.0912],\n",
      "          [ 0.7248,  0.8789,  0.8104,  ...,  0.0741,  0.1254,  0.1768],\n",
      "          [ 0.5193,  0.7419,  0.6563,  ...,  0.1939,  0.2282,  0.2624],\n",
      "          ...,\n",
      "          [-0.1486, -0.1486, -0.1657,  ..., -0.8335, -0.9705, -1.0048],\n",
      "          [-0.1828, -0.1657, -0.1486,  ..., -0.9363, -1.0733, -1.0219],\n",
      "          [-0.1828, -0.1143, -0.1657,  ..., -1.0219, -1.0219, -0.9705]],\n",
      "\n",
      "         [[ 0.6254,  0.9230,  0.7654,  ...,  0.1001,  0.1352,  0.2052],\n",
      "          [ 0.6429,  0.8004,  0.7304,  ...,  0.1877,  0.2402,  0.2927],\n",
      "          [ 0.4328,  0.6604,  0.5728,  ...,  0.3102,  0.3452,  0.3803],\n",
      "          ...,\n",
      "          [-0.3375, -0.3375, -0.3550,  ..., -0.6527, -0.7927, -0.8277],\n",
      "          [-0.3725, -0.3550, -0.3901,  ..., -0.7577, -0.8978, -0.8452],\n",
      "          [-0.3725, -0.3375, -0.4076,  ..., -0.8452, -0.8452, -0.7927]],\n",
      "\n",
      "         [[ 0.7054,  1.0017,  0.8448,  ...,  0.2348,  0.2696,  0.3393],\n",
      "          [ 0.7576,  0.8797,  0.8099,  ...,  0.3219,  0.3742,  0.4265],\n",
      "          [ 0.5485,  0.7402,  0.6531,  ...,  0.4439,  0.4788,  0.5311],\n",
      "          ...,\n",
      "          [-0.5321, -0.5321, -0.5147,  ..., -0.3753, -0.5147, -0.5495],\n",
      "          [-0.5670, -0.5495, -0.5321,  ..., -0.4798, -0.6193, -0.5670],\n",
      "          [-0.5670, -0.5321, -0.5495,  ..., -0.5670, -0.5670, -0.5147]]],\n",
      "\n",
      "\n",
      "        [[[ 0.5536,  0.5536,  0.5536,  ..., -0.1828,  0.5193,  1.5297],\n",
      "          [ 0.5536,  0.5536,  0.5536,  ...,  0.7077,  0.7933,  0.5536],\n",
      "          [ 0.5536,  0.5536,  0.5536,  ...,  0.6221,  0.8961,  0.5193],\n",
      "          ...,\n",
      "          [-0.7650, -1.1247, -1.0048,  ..., -1.9809, -1.9809, -1.9809],\n",
      "          [-1.6555, -1.5357, -1.3815,  ..., -1.9467, -1.9295, -1.9638],\n",
      "          [-1.4672, -1.5185, -0.8507,  ..., -1.9124, -1.8953, -1.9467]],\n",
      "\n",
      "         [[ 1.5707,  1.5707,  1.5707,  ..., -0.1800,  0.5728,  1.6232],\n",
      "          [ 1.5707,  1.5707,  1.5707,  ...,  0.7654,  0.8529,  0.6254],\n",
      "          [ 1.5707,  1.5707,  1.5707,  ...,  0.6779,  0.9580,  0.5903],\n",
      "          ...,\n",
      "          [-0.2325, -0.9853, -1.1429,  ..., -1.8606, -1.8606, -1.8606],\n",
      "          [-1.1429, -1.4055, -1.4930,  ..., -1.8256, -1.8081, -1.8431],\n",
      "          [-0.9503, -1.3880, -0.9503,  ..., -1.7906, -1.7731, -1.8256]],\n",
      "\n",
      "         [[ 2.6400,  2.6400,  2.6400,  ..., -0.0615,  0.7228,  1.7860],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  0.8797,  1.0017,  0.7925],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  0.7925,  1.1062,  0.7576],\n",
      "          ...,\n",
      "          [ 0.0605, -0.5495, -0.6890,  ..., -1.6476, -1.6476, -1.6476],\n",
      "          [-0.8458, -0.9678, -1.0550,  ..., -1.6127, -1.5953, -1.6302],\n",
      "          [-0.6541, -0.9504, -0.5147,  ..., -1.5779, -1.5604, -1.6127]]],\n",
      "\n",
      "\n",
      "        [[[-0.6281, -0.6965, -0.5596,  ...,  2.1804,  2.1804,  2.1804],\n",
      "          [-0.3541, -1.1932, -0.8164,  ...,  2.1804,  2.1804,  2.1804],\n",
      "          [-0.5082, -1.1760, -0.9534,  ...,  2.1804,  2.1804,  2.1804],\n",
      "          ...,\n",
      "          [-0.8507, -0.8507, -0.8164,  ..., -0.7822, -0.9192, -1.0048],\n",
      "          [-0.7650, -0.7822, -0.7650,  ..., -0.9020, -1.0733, -1.1760],\n",
      "          [-0.6452, -0.6794, -0.7993,  ..., -1.0904, -1.1760, -1.2959]],\n",
      "\n",
      "         [[-0.5126, -0.5826, -0.4426,  ...,  2.3585,  2.3585,  2.3585],\n",
      "          [-0.2325, -1.0903, -0.7052,  ...,  2.3585,  2.3585,  2.3585],\n",
      "          [-0.3901, -1.0728, -0.8452,  ...,  2.3585,  2.3585,  2.3585],\n",
      "          ...,\n",
      "          [-0.7402, -0.7402, -0.7052,  ..., -0.6702, -0.8102, -0.8978],\n",
      "          [-0.6527, -0.6702, -0.6527,  ..., -0.7927, -0.9678, -1.0728],\n",
      "          [-0.5301, -0.5651, -0.6877,  ..., -0.9853, -1.0728, -1.1954]],\n",
      "\n",
      "         [[-0.2881, -0.3578, -0.2184,  ...,  2.5703,  2.5703,  2.5703],\n",
      "          [-0.0092, -0.8633, -0.4798,  ...,  2.5703,  2.5703,  2.5703],\n",
      "          [-0.1661, -0.8458, -0.6193,  ...,  2.5703,  2.5703,  2.5703],\n",
      "          ...,\n",
      "          [-0.5147, -0.5147, -0.4798,  ..., -0.4450, -0.5844, -0.6715],\n",
      "          [-0.4275, -0.4450, -0.4275,  ..., -0.5670, -0.7413, -0.8458],\n",
      "          [-0.3055, -0.3404, -0.4624,  ..., -0.7587, -0.8458, -0.9678]]],\n",
      "\n",
      "\n",
      "        [[[-1.7925, -1.8268, -1.9638,  ...,  0.9474,  0.6221,  1.3242],\n",
      "          [-1.6727, -1.6727, -1.8439,  ...,  0.9474,  1.3413,  1.3413],\n",
      "          [-1.6898, -1.5699, -1.6384,  ...,  1.1358,  1.0844,  0.9646],\n",
      "          ...,\n",
      "          [-0.7993, -0.9192, -0.1657,  ..., -0.8335, -1.0733, -0.4911],\n",
      "          [ 0.0741,  0.1254,  0.1939,  ..., -1.0048, -0.6623, -0.3883],\n",
      "          [-0.0972,  0.0227,  0.4851,  ..., -0.9363, -0.7479, -0.4054]],\n",
      "\n",
      "         [[-1.7031, -1.7381, -1.8782,  ...,  1.0630,  0.7304,  1.4482],\n",
      "          [-1.5805, -1.5805, -1.7556,  ...,  1.0630,  1.4657,  1.4657],\n",
      "          [-1.6856, -1.5455, -1.6155,  ...,  1.3431,  1.2906,  1.1506],\n",
      "          ...,\n",
      "          [-0.6001, -0.7227,  0.0301,  ..., -0.1800, -0.4251,  0.1702],\n",
      "          [ 0.2927,  0.3452,  0.3978,  ..., -0.3725, -0.0049,  0.2752],\n",
      "          [ 0.1176,  0.2402,  0.6954,  ..., -0.3025, -0.0924,  0.2927]],\n",
      "\n",
      "         [[-1.5081, -1.5430, -1.6824,  ...,  1.3328,  1.0365,  1.7511],\n",
      "          [-1.3861, -1.3861, -1.5604,  ...,  1.3677,  1.7685,  1.7685],\n",
      "          [-1.3861, -1.2990, -1.3687,  ...,  1.4374,  1.3851,  1.2805],\n",
      "          ...,\n",
      "          [-0.3055, -0.4275,  0.3045,  ..., -1.1247, -1.3861, -0.8284],\n",
      "          [ 0.5834,  0.6356,  0.6705,  ..., -1.2641, -0.9504, -0.7238],\n",
      "          [ 0.4091,  0.5136,  0.9668,  ..., -1.1596, -1.0376, -0.6890]]]]) tensor([[0.6186, 0.3758, 0.6315,  ..., 0.4427, 0.3881, 0.8481],\n",
      "        [0.6970, 0.6799, 0.7978,  ..., 0.6279, 0.6441, 0.6209],\n",
      "        [0.4221, 0.7121, 0.6173,  ..., 0.4169, 0.4979, 0.2564],\n",
      "        [0.5404, 0.5239, 0.6328,  ..., 0.3501, 0.6858, 0.5658]])\n",
      "----\n",
      "['1490659882930594965', '1489840919146919234', '1487676925685022333', '1480941788440054562'] tensor([[[[ 0.1597,  0.1768,  0.1254,  ..., -0.7308, -0.6623, -0.7137],\n",
      "          [ 0.1939,  0.1939,  0.1597,  ..., -0.7993, -0.7822, -0.7479],\n",
      "          [ 0.2111,  0.2282,  0.2111,  ..., -0.8335, -0.8849, -0.8678],\n",
      "          ...,\n",
      "          [-1.8268, -1.8439, -1.8097,  ..., -1.1589, -0.8849, -0.8507],\n",
      "          [-1.8268, -1.8268, -1.8097,  ..., -1.4329, -1.1760, -0.7308],\n",
      "          [-1.8268, -1.8268, -1.8097,  ..., -1.4500, -1.1418,  0.4337]],\n",
      "\n",
      "         [[ 1.5007,  1.4657,  1.4132,  ...,  0.7479,  0.8179,  0.6779],\n",
      "          [ 1.4832,  1.4832,  1.4657,  ...,  0.6954,  0.7129,  0.6779],\n",
      "          [ 1.4832,  1.5007,  1.4832,  ...,  0.6604,  0.6078,  0.6078],\n",
      "          ...,\n",
      "          [-1.6506, -1.6681, -1.6331,  ..., -1.0203, -0.7402, -0.7402],\n",
      "          [-1.6506, -1.6506, -1.6331,  ..., -1.3004, -1.0203, -0.6176],\n",
      "          [-1.6506, -1.6506, -1.5980,  ..., -1.3004, -0.9853,  0.5728]],\n",
      "\n",
      "         [[ 2.6400,  2.6400,  2.6400,  ...,  2.1171,  2.1868,  2.0823],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.0648,  2.0823,  2.0648],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.0474,  1.9951,  1.9428],\n",
      "          ...,\n",
      "          [-1.0724, -1.0898, -1.0724,  ..., -0.5844, -0.3055, -0.3404],\n",
      "          [-1.0724, -1.0724, -1.0724,  ..., -0.8633, -0.6367, -0.2184],\n",
      "          [-1.0724, -1.0724, -1.0550,  ..., -0.9156, -0.6018,  0.9319]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2385,  1.2385,  1.2385,  ...,  1.3242,  1.3242,  1.3242],\n",
      "          [ 1.3070,  1.3070,  1.3070,  ...,  1.3242,  1.3242,  1.3242],\n",
      "          [ 1.3927,  1.3927,  1.3927,  ...,  1.3070,  1.3070,  1.3070],\n",
      "          ...,\n",
      "          [-1.9124, -1.8953, -1.8782,  ..., -0.0116, -0.0972, -0.1143],\n",
      "          [-1.9124, -1.8953, -1.8953,  ..., -0.0972, -0.1143, -0.1486],\n",
      "          [-1.9124, -1.9124, -1.8953,  ..., -0.1143, -0.1314, -0.2171]],\n",
      "\n",
      "         [[ 1.4657,  1.4657,  1.4657,  ...,  1.5007,  1.5007,  1.5007],\n",
      "          [ 1.5357,  1.5357,  1.5357,  ...,  1.5007,  1.5007,  1.5007],\n",
      "          [ 1.6232,  1.6232,  1.6232,  ...,  1.4832,  1.4832,  1.4832],\n",
      "          ...,\n",
      "          [-1.7906, -1.7906, -1.8081,  ...,  0.0651, -0.0224, -0.0399],\n",
      "          [-1.7906, -1.7906, -1.7906,  ..., -0.0224, -0.0399, -0.0749],\n",
      "          [-1.7906, -1.7906, -1.8081,  ..., -0.0399, -0.0574, -0.1450]],\n",
      "\n",
      "         [[ 1.7337,  1.7337,  1.7337,  ...,  1.7860,  1.7860,  1.7860],\n",
      "          [ 1.8034,  1.8034,  1.8034,  ...,  1.7860,  1.7860,  1.7860],\n",
      "          [ 1.8905,  1.8905,  1.8905,  ...,  1.7685,  1.7685,  1.7685],\n",
      "          ...,\n",
      "          [-1.6476, -1.6476, -1.6476,  ...,  0.1999,  0.1128,  0.0953],\n",
      "          [-1.6476, -1.6476, -1.6476,  ...,  0.1128,  0.0953,  0.0605],\n",
      "          [-1.6127, -1.6127, -1.6127,  ...,  0.0953,  0.0779, -0.0092]]],\n",
      "\n",
      "\n",
      "        [[[-0.5082, -0.5424, -1.0219,  ..., -1.6213, -1.6384, -1.6555],\n",
      "          [-0.5767, -0.5596, -1.0219,  ..., -1.6213, -1.6384, -1.6384],\n",
      "          [-0.5938, -0.5938, -0.9877,  ..., -1.6213, -1.6213, -1.6213],\n",
      "          ...,\n",
      "          [ 1.2557,  0.9988,  1.1358,  ...,  0.5022,  0.4337,  0.3481],\n",
      "          [ 1.5810,  1.5982,  1.2899,  ...,  0.6392,  0.5707,  0.4851],\n",
      "          [ 1.2899,  1.3755,  1.2557,  ...,  0.5878,  0.5364,  0.4337]],\n",
      "\n",
      "         [[-1.4580, -1.2479, -1.4755,  ..., -1.4755, -1.4755, -1.4930],\n",
      "          [-1.4930, -1.2479, -1.4755,  ..., -1.4755, -1.4755, -1.4755],\n",
      "          [-1.2129, -1.0553, -1.2654,  ..., -1.4930, -1.4930, -1.4930],\n",
      "          ...,\n",
      "          [ 1.2731,  1.0980,  1.2731,  ...,  0.4503,  0.3803,  0.2927],\n",
      "          [ 1.6057,  1.6758,  1.3957,  ...,  0.5903,  0.5203,  0.4328],\n",
      "          [ 1.3081,  1.4482,  1.3606,  ...,  0.5378,  0.4853,  0.3803]],\n",
      "\n",
      "         [[-0.4624, -0.2184, -0.4275,  ..., -0.6715, -0.6367, -0.6018],\n",
      "          [-0.4624, -0.2184, -0.4275,  ..., -0.6715, -0.6367, -0.5844],\n",
      "          [-0.5670, -0.2881, -0.4101,  ..., -0.5495, -0.5495, -0.5844],\n",
      "          ...,\n",
      "          [ 1.8557,  1.6465,  1.8034,  ...,  1.1934,  1.1237,  1.0365],\n",
      "          [ 2.1868,  2.2391,  1.9428,  ...,  1.3328,  1.2631,  1.1759],\n",
      "          [ 1.8905,  2.0125,  1.9080,  ...,  1.2805,  1.2282,  1.1237]]],\n",
      "\n",
      "\n",
      "        [[[-0.2684, -1.1075, -0.9705,  ..., -0.8164, -0.5596,  0.3481],\n",
      "          [ 0.2624, -0.7308, -0.6623,  ..., -0.2342, -0.6109,  0.8447],\n",
      "          [ 0.0227,  0.1768, -0.4397,  ..., -0.6281, -1.1589,  0.1768],\n",
      "          ...,\n",
      "          [-1.5357, -1.5870, -1.4843,  ..., -1.3644, -1.3815, -1.4329],\n",
      "          [-1.5357, -1.6042, -1.5014,  ..., -1.3302, -1.3644, -1.4329],\n",
      "          [-1.5528, -1.6213, -1.5528,  ..., -1.3130, -1.3815, -1.3987]],\n",
      "\n",
      "         [[-0.5476, -1.4230, -1.1429,  ..., -0.5301, -0.3025,  0.5903],\n",
      "          [-0.0749, -1.1078, -0.8627,  ...,  0.0651, -0.4076,  1.0630],\n",
      "          [-0.3725, -0.2500, -0.6702,  ..., -0.3725, -0.9678,  0.3452],\n",
      "          ...,\n",
      "          [-1.1954, -1.2654, -1.1604,  ..., -1.0028, -1.0203, -1.0728],\n",
      "          [-1.1954, -1.2829, -1.1779,  ..., -0.9678, -1.0028, -1.0728],\n",
      "          [-1.2129, -1.3004, -1.2304,  ..., -0.9503, -1.0203, -1.0378]],\n",
      "\n",
      "         [[-0.4624, -1.3687, -0.8981,  ...,  0.3219,  0.5485,  1.4374],\n",
      "          [-0.0441, -1.0724, -0.6367,  ...,  0.9145,  0.4788,  1.9254],\n",
      "          [-0.3404, -0.2532, -0.4624,  ...,  0.5311, -0.0790,  1.2282],\n",
      "          ...,\n",
      "          [-0.4624, -0.4450, -0.3753,  ..., -0.0615, -0.0790, -0.1312],\n",
      "          [-0.4624, -0.4624, -0.3927,  ..., -0.0267, -0.0615, -0.1312],\n",
      "          [-0.4798, -0.4798, -0.4450,  ..., -0.0092, -0.0790, -0.0964]]]]) tensor([[0.3981, 0.6766, 0.4924,  ..., 0.4012, 0.2936, 0.6633],\n",
      "        [0.6508, 0.5582, 0.3999,  ..., 0.3593, 0.4761, 0.3679],\n",
      "        [0.7360, 0.3540, 0.4759,  ..., 0.3833, 0.6536, 0.7549],\n",
      "        [0.4798, 0.4400, 0.8161,  ..., 0.3789, 0.5432, 0.5476]])\n",
      "----\n",
      "['1489658491986857252', '1481007530145672379', '1481040658940297881', '1481139011903867292'] tensor([[[[-0.8164, -0.9020, -0.7993,  ...,  2.2489,  2.2489,  2.0777],\n",
      "          [-0.6452, -0.7993, -0.8335,  ...,  1.2043,  2.2489,  2.2489],\n",
      "          [-0.6452, -0.6109, -0.6965,  ..., -0.7479,  1.2214,  2.2318],\n",
      "          ...,\n",
      "          [ 1.0844,  1.0844,  1.1015,  ...,  1.3927,  1.3242,  1.2385],\n",
      "          [ 1.0673,  1.0844,  1.1015,  ...,  1.1187,  1.0502,  0.9817],\n",
      "          [ 1.0331,  1.0502,  1.0673,  ...,  1.0673,  1.0331,  1.0159]],\n",
      "\n",
      "         [[-0.5476, -0.6702, -0.6001,  ...,  1.9734,  1.7983,  1.5707],\n",
      "          [-0.4426, -0.6001, -0.6702,  ...,  0.7479,  2.0434,  2.1485],\n",
      "          [-0.4776, -0.4776, -0.6001,  ..., -1.1779,  0.7829,  1.8158],\n",
      "          ...,\n",
      "          [ 1.2556,  1.2556,  1.2731,  ...,  1.1506,  1.0805,  0.9930],\n",
      "          [ 1.2381,  1.2556,  1.2731,  ...,  0.9055,  0.8354,  0.7654],\n",
      "          [ 1.2031,  1.2206,  1.2381,  ...,  0.9230,  0.8880,  0.8704]],\n",
      "\n",
      "         [[ 0.2173,  0.0605,  0.1476,  ...,  2.0648,  1.8905,  1.6640],\n",
      "          [ 0.3393,  0.1476,  0.0953,  ...,  0.8971,  2.1868,  2.2914],\n",
      "          [ 0.3219,  0.2871,  0.1651,  ..., -0.9853,  0.9842,  1.9951],\n",
      "          ...,\n",
      "          [ 1.1934,  1.1934,  1.2108,  ...,  1.6814,  1.6117,  1.5245],\n",
      "          [ 1.1759,  1.1934,  1.2108,  ...,  1.4200,  1.3502,  1.2805],\n",
      "          [ 1.1411,  1.1585,  1.1759,  ...,  1.4200,  1.3851,  1.3677]]],\n",
      "\n",
      "\n",
      "        [[[ 1.7865,  1.8722,  1.6324,  ..., -0.1657, -0.0116,  0.0227],\n",
      "          [ 2.1290,  2.2489,  1.9578,  ...,  0.0912,  0.1597,  0.1768],\n",
      "          [ 1.3927,  1.7865,  1.9749,  ...,  0.1083,  0.2453,  0.3309],\n",
      "          ...,\n",
      "          [ 1.6667,  1.6495,  1.6324,  ..., -0.6623, -0.9020, -0.6623],\n",
      "          [ 1.6838,  1.7865,  1.8208,  ..., -0.0458, -0.3541, -0.6452],\n",
      "          [ 1.7180,  1.8208,  1.7523,  ...,  0.5878, -0.0116, -0.1486]],\n",
      "\n",
      "         [[ 1.8683,  1.9909,  1.7983,  ..., -1.7206, -1.7031, -1.7731],\n",
      "          [ 2.1835,  2.3410,  2.0609,  ..., -1.8256, -1.8782, -1.9657],\n",
      "          [ 1.3782,  1.7808,  1.9909,  ..., -2.0357, -2.0007, -1.9307],\n",
      "          ...,\n",
      "          [ 1.7983,  1.7808,  1.7633,  ..., -0.4601, -0.7052, -0.4601],\n",
      "          [ 1.8158,  1.9209,  1.9559,  ...,  0.1702, -0.1450, -0.4426],\n",
      "          [ 1.8508,  1.9559,  1.8859,  ...,  0.7829,  0.2052,  0.0651]],\n",
      "\n",
      "         [[ 1.9777,  2.0823,  1.8731,  ..., -1.2990, -1.2816, -1.3513],\n",
      "          [ 2.2566,  2.4134,  2.1171,  ..., -1.4384, -1.4733, -1.5604],\n",
      "          [ 1.4374,  1.8383,  2.0474,  ..., -1.6476, -1.5953, -1.5604],\n",
      "          ...,\n",
      "          [ 2.0300,  2.0125,  1.9951,  ..., -0.1312, -0.3753, -0.1312],\n",
      "          [ 2.0474,  2.1520,  2.1868,  ...,  0.4962,  0.1825, -0.1138],\n",
      "          [ 2.0823,  2.1868,  2.1171,  ...,  1.1237,  0.5311,  0.3916]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1872,  1.1872,  1.1700,  ...,  0.9988,  1.0159,  1.0331],\n",
      "          [ 1.1872,  1.1872,  1.1872,  ...,  1.0159,  1.0331,  1.0331],\n",
      "          [ 1.2043,  1.2043,  1.1872,  ...,  1.0331,  1.0331,  1.0502],\n",
      "          ...,\n",
      "          [ 1.8037,  1.8037,  1.8037,  ...,  1.4954,  1.4954,  1.4954],\n",
      "          [ 1.8037,  1.8037,  1.8037,  ...,  1.6153,  1.5982,  1.5810],\n",
      "          [ 1.8379,  1.8379,  1.8379,  ...,  1.6324,  1.6324,  1.6324]],\n",
      "\n",
      "         [[ 1.3081,  1.3081,  1.2906,  ...,  1.1331,  1.1506,  1.1681],\n",
      "          [ 1.3081,  1.3081,  1.3081,  ...,  1.1506,  1.1681,  1.1681],\n",
      "          [ 1.3256,  1.3256,  1.3081,  ...,  1.1681,  1.1681,  1.1856],\n",
      "          ...,\n",
      "          [ 1.9734,  1.9734,  1.9734,  ...,  1.6933,  1.6933,  1.6933],\n",
      "          [ 1.9734,  1.9734,  1.9734,  ...,  1.8158,  1.7983,  1.7808],\n",
      "          [ 1.9909,  1.9909,  1.9909,  ...,  1.7808,  1.7808,  1.7808]],\n",
      "\n",
      "         [[ 1.5420,  1.5420,  1.5245,  ...,  1.3154,  1.3328,  1.3502],\n",
      "          [ 1.5420,  1.5420,  1.5420,  ...,  1.3328,  1.3502,  1.3502],\n",
      "          [ 1.5594,  1.5594,  1.5420,  ...,  1.3502,  1.3502,  1.3677],\n",
      "          ...,\n",
      "          [ 2.1520,  2.1520,  2.1520,  ...,  1.8208,  1.8208,  1.8208],\n",
      "          [ 2.1520,  2.1520,  2.1520,  ...,  1.9428,  1.9254,  1.9080],\n",
      "          [ 2.1694,  2.1694,  2.1694,  ...,  1.9603,  1.9603,  1.9603]]],\n",
      "\n",
      "\n",
      "        [[[-2.0494, -2.0152, -1.9980,  ..., -1.5185, -1.5185, -1.5185],\n",
      "          [-2.0837, -2.0665, -2.0494,  ..., -1.5014, -1.5185, -1.5357],\n",
      "          [-2.0837, -2.1008, -2.1008,  ..., -1.5014, -1.5185, -1.5528],\n",
      "          ...,\n",
      "          [ 0.1426,  0.6563,  0.1597,  ..., -1.4329, -1.3644, -2.1179],\n",
      "          [ 0.1939,  0.2796,  0.1426,  ..., -1.6898, -1.2445, -2.1179],\n",
      "          [-0.9192,  1.1015, -0.3883,  ..., -1.9467, -1.2959, -2.1179]],\n",
      "\n",
      "         [[-1.9657, -1.9307, -1.9132,  ..., -1.5455, -1.5455, -1.5455],\n",
      "          [-2.0007, -1.9832, -1.9657,  ..., -1.5280, -1.5455, -1.5630],\n",
      "          [-2.0007, -2.0182, -2.0182,  ..., -1.5280, -1.5455, -1.5805],\n",
      "          ...,\n",
      "          [-1.0203, -0.0924,  0.0476,  ..., -1.3004, -1.2304, -2.0182],\n",
      "          [-1.0903, -1.3880, -0.8627,  ..., -1.5630, -1.1078, -2.0007],\n",
      "          [-1.8782, -1.0203, -2.0357,  ..., -1.7731, -1.1078, -1.9482]],\n",
      "\n",
      "         [[-1.7347, -1.6999, -1.6824,  ..., -1.4210, -1.4210, -1.4210],\n",
      "          [-1.7696, -1.7522, -1.7347,  ..., -1.4036, -1.4210, -1.4384],\n",
      "          [-1.7696, -1.7870, -1.7870,  ..., -1.4036, -1.4210, -1.4559],\n",
      "          ...,\n",
      "          [-0.7761,  0.0779,  0.0779,  ..., -1.1596, -1.0898, -1.8044],\n",
      "          [-0.7064, -0.8284, -0.5321,  ..., -1.4210, -0.9678, -1.8044],\n",
      "          [-1.5256, -0.3055, -1.6999,  ..., -1.6476, -0.9853, -1.8044]]]]) tensor([[0.6603, 0.4578, 0.5736,  ..., 0.4392, 0.6887, 0.4445],\n",
      "        [0.3526, 0.5628, 0.6894,  ..., 0.4976, 0.2709, 0.4986],\n",
      "        [0.6360, 0.6006, 0.2666,  ..., 0.4850, 0.4056, 0.2369],\n",
      "        [0.5753, 0.4658, 0.7532,  ..., 0.4707, 0.7467, 0.4505]])\n",
      "----\n",
      "['1490075258878610944', '1490699758992372367', '1489886562208852834', '1481097035704453947'] tensor([[[[ 1.7694,  0.8104,  0.5878,  ...,  0.1597,  0.2796,  0.3138],\n",
      "          [ 0.6221, -0.0458,  0.6049,  ...,  0.1597,  0.2111,  0.2796],\n",
      "          [ 0.6734,  0.0398,  0.2453,  ...,  0.0741, -0.0801, -0.1828],\n",
      "          ...,\n",
      "          [ 1.5810,  1.5125,  1.5125,  ..., -1.7925, -0.0287, -0.2171],\n",
      "          [ 1.6324,  1.5982,  1.5982,  ..., -0.5424,  0.1426,  0.6049],\n",
      "          [ 1.6667,  1.7009,  1.6838,  ...,  1.3584,  1.4612,  1.5810]],\n",
      "\n",
      "         [[ 1.9209,  0.7129,  0.1877,  ...,  0.4853,  0.5728,  0.6078],\n",
      "          [ 0.3627, -0.3725,  0.2752,  ...,  0.6254,  0.6779,  0.7304],\n",
      "          [ 0.4153, -0.2675, -0.0749,  ...,  0.5378,  0.3803,  0.2752],\n",
      "          ...,\n",
      "          [ 1.7633,  1.6933,  1.6933,  ..., -1.7381,  0.0126, -0.1975],\n",
      "          [ 1.8158,  1.7808,  1.7808,  ..., -0.4601,  0.2052,  0.6429],\n",
      "          [ 1.8508,  1.8859,  1.8683,  ...,  1.5007,  1.5532,  1.6583]],\n",
      "\n",
      "         [[ 2.2740,  1.1934,  0.7228,  ...,  0.7751,  0.8797,  0.9145],\n",
      "          [ 1.0714,  0.4614,  1.0365,  ...,  0.9668,  1.0191,  1.1237],\n",
      "          [ 1.0888,  0.5136,  0.6531,  ...,  0.8622,  0.7228,  0.6182],\n",
      "          ...,\n",
      "          [ 1.8383,  1.7685,  1.7685,  ..., -1.8044, -0.1487, -0.3927],\n",
      "          [ 1.8905,  1.8557,  1.8557,  ..., -0.6715, -0.0092,  0.4091],\n",
      "          [ 1.9254,  1.9603,  1.9428,  ...,  1.2282,  1.2980,  1.3677]]],\n",
      "\n",
      "\n",
      "        [[[ 2.0948,  2.0263,  1.8037,  ..., -1.8610, -1.8610, -1.8439],\n",
      "          [ 2.0948,  2.0263,  1.8208,  ..., -1.8610, -1.8610, -1.8610],\n",
      "          [ 2.0948,  2.0263,  1.8379,  ..., -1.8610, -1.8610, -1.8782],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.3936,  ...,  0.7654,  0.7654,  0.7304],\n",
      "          [ 2.4286,  2.4286,  2.4111,  ...,  0.8004,  0.7654,  0.7654],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  0.8004,  0.8004,  0.7829],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[ 2.6400,  2.6400,  2.6400,  ...,  2.3960,  2.3960,  2.3786],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.4134,  2.3960,  2.3960],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.3786,  2.3786,  2.3611],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400]]],\n",
      "\n",
      "\n",
      "        [[[-1.1589, -1.1418, -1.1247,  ..., -0.2684, -0.2342, -0.2513],\n",
      "          [-1.1075, -1.1075, -1.0904,  ..., -0.2171, -0.2171, -0.0972],\n",
      "          [-1.1247, -1.1075, -1.0904,  ..., -0.1828, -0.1657, -0.0801],\n",
      "          ...,\n",
      "          [-0.4568, -1.1075, -1.3130,  ...,  0.7248,  0.5022,  0.6392],\n",
      "          [-0.4911, -1.1075, -1.3302,  ...,  0.6563,  0.6734,  0.7077],\n",
      "          [-0.5253, -1.0904, -1.3130,  ...,  0.4166,  0.7933,  0.6734]],\n",
      "\n",
      "         [[-1.0903, -1.0728, -1.0553,  ..., -0.1275, -0.0924, -0.1625],\n",
      "          [-1.0903, -1.0903, -1.0728,  ..., -0.1099, -0.1099, -0.1099],\n",
      "          [-1.1078, -1.0903, -1.0728,  ..., -0.0749, -0.0574, -0.0924],\n",
      "          ...,\n",
      "          [-0.4076, -1.0203, -1.1604,  ...,  0.9930,  0.7654,  0.8354],\n",
      "          [-0.3901, -0.9853, -1.1429,  ...,  0.9230,  0.9405,  0.9230],\n",
      "          [-0.3901, -0.9328, -1.0903,  ...,  0.6779,  1.0630,  0.8880]],\n",
      "\n",
      "         [[-0.8110, -0.7936, -0.7761,  ..., -0.0441, -0.0092,  0.0779],\n",
      "          [-0.7587, -0.7587, -0.7413,  ...,  0.0779,  0.0779,  0.0605],\n",
      "          [-0.7761, -0.7587, -0.7413,  ...,  0.1128,  0.1302,  0.0779],\n",
      "          ...,\n",
      "          [ 0.0779, -0.5495, -0.6715,  ...,  1.3502,  1.1237,  1.2108],\n",
      "          [ 0.1128, -0.4450, -0.5844,  ...,  1.2805,  1.2980,  1.3328],\n",
      "          [ 0.1825, -0.3753, -0.5321,  ...,  1.0714,  1.4548,  1.2980]]],\n",
      "\n",
      "\n",
      "        [[[-0.8507, -1.2788, -1.2445,  ..., -1.1075, -1.1418, -1.2103],\n",
      "          [-0.4568, -1.0390, -1.3644,  ..., -1.2274, -1.0562, -1.1247],\n",
      "          [-0.7137, -1.0733, -1.2959,  ..., -1.0733, -1.0390, -1.1589],\n",
      "          ...,\n",
      "          [ 2.2147,  2.2147,  2.2147,  ...,  2.1633,  2.2147,  2.2147],\n",
      "          [ 2.2147,  2.2147,  2.2147,  ...,  2.1462,  2.2147,  2.2147],\n",
      "          [ 2.2147,  2.2147,  2.2147,  ...,  2.1633,  2.2147,  2.2147]],\n",
      "\n",
      "         [[-1.0903, -1.4580, -1.3880,  ..., -1.2829, -1.3004, -1.3704],\n",
      "          [-0.6877, -1.1779, -1.4405,  ..., -1.4230, -1.1954, -1.2654],\n",
      "          [-0.9503, -1.2129, -1.3704,  ..., -1.3004, -1.2304, -1.3529],\n",
      "          ...,\n",
      "          [ 2.3936,  2.3936,  2.3936,  ...,  2.4286,  2.3936,  2.3936],\n",
      "          [ 2.3936,  2.3936,  2.3936,  ...,  2.4286,  2.3936,  2.3936],\n",
      "          [ 2.3936,  2.3936,  2.3936,  ...,  2.4286,  2.3936,  2.3936]],\n",
      "\n",
      "         [[-0.8284, -1.2119, -1.1596,  ..., -0.8284, -0.9504, -1.0550],\n",
      "          [-0.4275, -0.9504, -1.2293,  ..., -1.0898, -1.1247, -1.1944],\n",
      "          [-0.6890, -0.9853, -1.1596,  ..., -1.0027, -1.1770, -1.2990],\n",
      "          ...,\n",
      "          [ 2.6051,  2.6051,  2.6051,  ...,  2.5180,  2.5703,  2.5703],\n",
      "          [ 2.6051,  2.6051,  2.6051,  ...,  2.4657,  2.5703,  2.5703],\n",
      "          [ 2.6051,  2.6051,  2.6051,  ...,  2.4831,  2.5703,  2.5703]]]]) tensor([[0.0742, 0.4360, 0.8360,  ..., 0.3571, 0.6121, 0.5062],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.8184, 0.6175, 0.7848,  ..., 0.4041, 0.3438, 0.6586],\n",
      "        [0.5060, 0.5219, 0.7509,  ..., 0.7352, 0.9242, 0.6562]])\n",
      "----\n",
      "['1487635893179409262', '1489856820506815985', '1481179139212957959', '1489896267786304778'] tensor([[[[ 0.7762,  1.7180,  1.9407,  ...,  1.5639,  1.5982,  1.7009],\n",
      "          [ 1.3927,  2.1119,  2.1975,  ...,  1.1529,  1.4440,  1.7180],\n",
      "          [ 1.2214,  1.7009,  1.7352,  ...,  0.2453,  0.5193,  1.1187],\n",
      "          ...,\n",
      "          [ 0.4337,  0.2624,  0.7762,  ...,  0.8789,  0.9474,  0.5364],\n",
      "          [-0.1486, -0.6794, -0.1657,  ...,  0.7248,  1.1700,  1.2557],\n",
      "          [-0.9020, -1.4329, -0.9705,  ...,  0.7077,  1.1700,  1.3070]],\n",
      "\n",
      "         [[-2.0357, -2.0357, -2.0357,  ..., -1.6681, -1.5630, -1.5630],\n",
      "          [-2.0357, -2.0357, -2.0357,  ..., -1.8256, -1.6681, -1.5630],\n",
      "          [-1.7381, -1.9307, -1.9132,  ..., -1.9482, -1.7731, -1.5105],\n",
      "          ...,\n",
      "          [-1.1604, -1.1604, -1.4230,  ..., -1.7556, -1.6856, -1.8957],\n",
      "          [-1.5805, -1.6506, -1.7381,  ..., -1.9832, -1.7556, -1.6681],\n",
      "          [-1.7556, -1.7556, -1.7556,  ..., -1.8431, -1.8081, -1.7731]],\n",
      "\n",
      "         [[-1.8044, -1.5779, -1.3513,  ..., -1.2467, -1.1596, -1.1596],\n",
      "          [-1.5430, -1.3339, -1.1944,  ..., -1.4907, -1.2467, -1.1596],\n",
      "          [-1.2990, -1.2293, -1.2467,  ..., -1.8044, -1.6302, -1.3339],\n",
      "          ...,\n",
      "          [-0.1138, -0.1312, -0.0964,  ..., -1.6302, -1.5256, -1.7870],\n",
      "          [-0.5844, -0.7761, -0.6193,  ..., -1.8044, -1.4907, -1.3861],\n",
      "          [-0.9853, -1.1073, -0.9504,  ..., -1.7522, -1.5256, -1.4384]]],\n",
      "\n",
      "\n",
      "        [[[-0.8849, -0.8849, -0.8849,  ..., -1.0904, -0.9877, -0.8507],\n",
      "          [-0.8849, -0.8507, -0.8507,  ..., -1.1418, -1.0562, -0.9020],\n",
      "          [-0.8507, -0.8507, -0.8335,  ..., -1.1589, -1.0904, -0.9192],\n",
      "          ...,\n",
      "          [-1.8610, -1.6898, -1.5528,  ..., -1.6555, -1.6384, -1.6384],\n",
      "          [-1.5699, -1.6213, -1.6727,  ..., -1.6727, -1.6384, -1.6384],\n",
      "          [-1.2959, -1.7069, -1.7583,  ..., -1.7069, -1.7240, -1.7412]],\n",
      "\n",
      "         [[-0.1975, -0.1975, -0.1975,  ..., -0.5476, -0.4076, -0.2325],\n",
      "          [-0.1975, -0.2150, -0.2150,  ..., -0.6001, -0.4776, -0.2850],\n",
      "          [-0.1975, -0.1975, -0.2150,  ..., -0.6176, -0.5126, -0.3025],\n",
      "          ...,\n",
      "          [-1.7906, -1.6155, -1.4755,  ..., -1.6155, -1.5980, -1.5980],\n",
      "          [-1.4930, -1.5455, -1.5980,  ..., -1.5805, -1.5455, -1.5455],\n",
      "          [-1.2129, -1.6331, -1.6856,  ..., -1.6155, -1.6331, -1.6506]],\n",
      "\n",
      "         [[ 1.1934,  1.2282,  1.2631,  ...,  0.6182,  0.7751,  0.9668],\n",
      "          [ 1.1934,  1.2282,  1.2282,  ...,  0.5659,  0.7054,  0.9145],\n",
      "          [ 1.1585,  1.1934,  1.1934,  ...,  0.5485,  0.6705,  0.8971],\n",
      "          ...,\n",
      "          [-1.6302, -1.4559, -1.3164,  ..., -1.5081, -1.4907, -1.4907],\n",
      "          [-1.3513, -1.4036, -1.4559,  ..., -1.4907, -1.4559, -1.4559],\n",
      "          [-1.0724, -1.4907, -1.5430,  ..., -1.5256, -1.5430, -1.5604]]],\n",
      "\n",
      "\n",
      "        [[[ 1.8722,  1.8550,  1.8722,  ...,  1.5810,  1.5810,  1.5810],\n",
      "          [ 1.8722,  1.8722,  1.8722,  ...,  1.5810,  1.5982,  1.5982],\n",
      "          [ 1.9064,  1.9064,  1.8722,  ...,  1.5982,  1.6153,  1.6324],\n",
      "          ...,\n",
      "          [ 0.7591,  0.7762,  0.8276,  ..., -0.7993, -0.6109, -0.3369],\n",
      "          [ 0.7248,  0.7762,  0.9132,  ...,  0.5707, -0.5082, -0.7822],\n",
      "          [ 0.9132,  0.7248,  0.8961,  ...,  0.2453, -0.0972, -0.1657]],\n",
      "\n",
      "         [[ 1.6583,  1.6758,  1.6933,  ...,  1.0455,  1.0455,  1.0455],\n",
      "          [ 1.6933,  1.6933,  1.6933,  ...,  1.0455,  1.0630,  1.0630],\n",
      "          [ 1.7283,  1.7283,  1.7458,  ...,  1.0630,  1.0805,  1.0980],\n",
      "          ...,\n",
      "          [-0.1625, -0.1450, -0.0924,  ..., -1.5805, -1.4405, -1.1429],\n",
      "          [-0.1625, -0.1099, -0.0399,  ..., -0.0049, -0.9328, -1.0553],\n",
      "          [-0.0049, -0.1975, -0.0399,  ..., -0.3200, -0.4951, -0.4251]],\n",
      "\n",
      "         [[ 1.4548,  1.4548,  1.4722,  ...,  0.6356,  0.6356,  0.6356],\n",
      "          [ 1.4722,  1.4722,  1.4722,  ...,  0.6356,  0.6531,  0.6531],\n",
      "          [ 1.5071,  1.5071,  1.5071,  ...,  0.6531,  0.6705,  0.6879],\n",
      "          ...,\n",
      "          [-1.8044, -1.7870, -1.7347,  ..., -1.4210, -1.3861, -1.4559],\n",
      "          [-1.5779, -1.4907, -1.2119,  ..., -0.7587, -1.5081, -1.4733],\n",
      "          [-1.6476, -1.8044, -1.5430,  ..., -1.1596, -1.1421, -0.8807]]],\n",
      "\n",
      "\n",
      "        [[[ 2.0605,  1.3070, -1.0904,  ...,  1.7694,  1.8208,  1.8379],\n",
      "          [ 1.7694,  1.3413, -0.8335,  ...,  1.8379,  1.8722,  1.9064],\n",
      "          [ 1.5297,  0.8789, -1.0219,  ...,  1.9407,  1.8893,  1.8550],\n",
      "          ...,\n",
      "          [-0.2513, -0.1143,  0.0056,  ..., -1.2959, -1.2788, -1.2445],\n",
      "          [-0.2684, -0.1486, -0.0287,  ..., -1.2959, -1.2959, -1.2788],\n",
      "          [-0.2342, -0.1999, -0.1143,  ..., -1.3302, -1.3473, -1.3473]],\n",
      "\n",
      "         [[ 2.2885,  1.5182, -0.9328,  ...,  0.8704,  0.9230,  0.9405],\n",
      "          [ 1.9909,  1.5532, -0.6702,  ...,  0.9405,  0.9755,  1.0105],\n",
      "          [ 1.7458,  1.0805, -0.8627,  ...,  1.0805,  1.0280,  0.9405],\n",
      "          ...,\n",
      "          [-1.1604, -1.0553, -0.9328,  ..., -1.1779, -1.1604, -1.1253],\n",
      "          [-1.1779, -1.0553, -0.9678,  ..., -1.1779, -1.1779, -1.1604],\n",
      "          [-1.1429, -1.1078, -1.0203,  ..., -1.2129, -1.2304, -1.2304]],\n",
      "\n",
      "         [[ 2.6226,  1.8557, -0.5495,  ...,  0.7751,  0.8274,  0.8448],\n",
      "          [ 2.3263,  1.9254, -0.2881,  ...,  0.8448,  0.8797,  0.9145],\n",
      "          [ 2.0823,  1.4548, -0.4798,  ...,  0.9842,  0.9319,  0.8971],\n",
      "          ...,\n",
      "          [-1.0027, -0.8807, -0.7936,  ..., -0.9156, -0.8981, -0.8633],\n",
      "          [-1.0201, -0.8981, -0.8284,  ..., -0.9156, -0.9156, -0.8981],\n",
      "          [-0.9853, -0.9504, -0.8981,  ..., -0.9156, -0.9330, -0.9330]]]]) tensor([[0.4530, 0.6268, 0.6910,  ..., 0.2464, 0.6173, 0.4443],\n",
      "        [1.0000, 0.5490, 0.5137,  ..., 0.5340, 0.5362, 0.4417],\n",
      "        [0.4726, 0.2794, 0.4342,  ..., 0.4051, 0.2379, 0.5426],\n",
      "        [0.6593, 0.4166, 0.3535,  ..., 0.1877, 0.5114, 0.3034]])\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "for x, y, z in train_loader:\n",
    "    print(x, y, z)\n",
    "    print('----')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3b7bce",
   "metadata": {},
   "source": [
    "#### Monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "49498bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"\n",
    "    Computes and stores the average and current value.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8481e23c",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f862e359",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_freq = 1 # how frequently to print loss value to screen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dfad29d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch, print_freq, plot_data, gpu):\n",
    "    batch_time = AverageMeter()\n",
    "    loss_meter = AverageMeter()\n",
    "\n",
    "    model.train()\n",
    "    \n",
    "    i = 0\n",
    "    end = time.time()\n",
    "    for i, (img_id, image, target) in enumerate(train_loader):\n",
    "        target_var = torch.autograd.Variable(target).cuda(GPU)\n",
    "        image_var = torch.autograd.Variable(image)\n",
    "\n",
    "        # compute output\n",
    "        output = model(image_var)\n",
    "        loss = criterion(output, target_var)\n",
    "        \n",
    "        # measure and record loss\n",
    "        # loss.data.item() => loss value\n",
    "        # image.size()[0] => batch size\n",
    "        loss_meter.update(loss.data.item(), image.size()[0])\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        \n",
    "        if i % print_freq == 0:\n",
    "            logger.info(f'Epoch: [{epoch}][{i}/{len(train_loader)}]')\n",
    "            logger.info(f'Train Loss: [loss.val={loss_meter.val}] [loss.avg={loss_meter.avg}]')\n",
    "            logger.info(f'Train Batch Time: [{batch_time.avg}]')\n",
    "            \n",
    "    plot_data['train_loss'][plot_data['epoch']] = loss_meter.avg\n",
    "    \n",
    "    return plot_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7938d2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion, print_freq, plot_data, gpu):\n",
    "    with torch.no_grad():\n",
    "        batch_time = AverageMeter()\n",
    "        loss_meter = AverageMeter()\n",
    "\n",
    "        # switch to evaluate mode\n",
    "        model.eval()\n",
    "\n",
    "        end = time.time()\n",
    "        for i, (img_id, image, target) in enumerate(val_loader):\n",
    "            target_var = torch.autograd.Variable(target).cuda(GPU)\n",
    "            image_var = torch.autograd.Variable(image)\n",
    "\n",
    "            # compute output\n",
    "            output = model(image_var)\n",
    "            loss = criterion(output, target_var)\n",
    "\n",
    "            # measure and record loss\n",
    "            loss_meter.update(loss.data.item(), image.size()[0])\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "            \n",
    "            if i % print_freq == 0:\n",
    "                logger.info(f'[{i}/{len(val_loader)}]')\n",
    "                logger.info(f'Val Loss: [loss.val={loss_meter.val}] [loss.avg={loss_meter.avg}]')\n",
    "                logger.info(f'Val Batch Time: [{batch_time.avg}]')\n",
    "        plot_data['val_loss'][plot_data['epoch']] = loss_meter.avg\n",
    "\n",
    "    return plot_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8b2f1ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(model, filename):\n",
    "    logger.info('Saving model checkpoint')\n",
    "    torch.save(model.state_dict(), filename + '.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7cab0934",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [0][0/5]\n",
      "Train Loss: [loss.val=0.9033564329147339] [loss.avg=0.9033564329147339]\n",
      "Train Batch Time: [5.152038335800171]\n",
      "Epoch: [0][1/5]\n",
      "Train Loss: [loss.val=2.469839096069336] [loss.avg=1.686597764492035]\n",
      "Train Batch Time: [2.6412642002105713]\n",
      "Epoch: [0][2/5]\n",
      "Train Loss: [loss.val=1.1740014553070068] [loss.avg=1.5157323280970256]\n",
      "Train Batch Time: [1.807596206665039]\n",
      "Epoch: [0][3/5]\n",
      "Train Loss: [loss.val=0.9941520094871521] [loss.avg=1.3853372484445572]\n",
      "Train Batch Time: [1.3903720378875732]\n",
      "Epoch: [0][4/5]\n",
      "Train Loss: [loss.val=1.0047762393951416] [loss.avg=1.309225046634674]\n",
      "Train Batch Time: [1.140198040008545]\n",
      "[0/5]\n",
      "Val Loss: [loss.val=534306548088832.0] [loss.avg=534306548088832.0]\n",
      "Val Batch Time: [0.14108562469482422]\n",
      "[1/5]\n",
      "Val Loss: [loss.val=594267244331008.0] [loss.avg=564286896209920.0]\n",
      "Val Batch Time: [0.09010207653045654]\n",
      "[2/5]\n",
      "Val Loss: [loss.val=439159734927360.0] [loss.avg=522577842449066.7]\n",
      "Val Batch Time: [0.0725092093149821]\n",
      "[3/5]\n",
      "Val Loss: [loss.val=450107237466112.0] [loss.avg=504460191203328.0]\n",
      "Val Batch Time: [0.06380146741867065]\n",
      "[4/5]\n",
      "Val Loss: [loss.val=456519657193472.0] [loss.avg=494872084401356.8]\n",
      "Val Batch Time: [0.05855903625488281]\n",
      "Epoch: [1][0/5]\n",
      "Train Loss: [loss.val=0.9550654888153076] [loss.avg=0.9550654888153076]\n",
      "Train Batch Time: [0.2354271411895752]\n",
      "Epoch: [1][1/5]\n",
      "Train Loss: [loss.val=0.9339392185211182] [loss.avg=0.9445023536682129]\n",
      "Train Batch Time: [0.18731355667114258]\n",
      "Epoch: [1][2/5]\n",
      "Train Loss: [loss.val=0.8602030277252197] [loss.avg=0.9164025783538818]\n",
      "Train Batch Time: [0.17149273554484049]\n",
      "Epoch: [1][3/5]\n",
      "Train Loss: [loss.val=0.8553681373596191] [loss.avg=0.9011439681053162]\n",
      "Train Batch Time: [0.16393834352493286]\n",
      "Epoch: [1][4/5]\n",
      "Train Loss: [loss.val=0.8167816996574402] [loss.avg=0.8842715144157409]\n",
      "Train Batch Time: [0.15863332748413086]\n",
      "[0/5]\n",
      "Val Loss: [loss.val=1367731200.0] [loss.avg=1367731200.0]\n",
      "Val Batch Time: [0.13389849662780762]\n",
      "[1/5]\n",
      "Val Loss: [loss.val=1284976128.0] [loss.avg=1326353664.0]\n",
      "Val Batch Time: [0.08630561828613281]\n",
      "[2/5]\n",
      "Val Loss: [loss.val=870500992.0] [loss.avg=1174402773.3333333]\n",
      "Val Batch Time: [0.06991457939147949]\n",
      "[3/5]\n",
      "Val Loss: [loss.val=923573696.0] [loss.avg=1111695504.0]\n",
      "Val Batch Time: [0.061770856380462646]\n",
      "[4/5]\n",
      "Val Loss: [loss.val=992417600.0] [loss.avg=1087839923.2]\n",
      "Val Batch Time: [0.057000350952148435]\n",
      "Epoch: [2][0/5]\n",
      "Train Loss: [loss.val=0.7160496115684509] [loss.avg=0.7160496115684509]\n",
      "Train Batch Time: [0.23025941848754883]\n",
      "Epoch: [2][1/5]\n",
      "Train Loss: [loss.val=0.7173337340354919] [loss.avg=0.7166916728019714]\n",
      "Train Batch Time: [0.1849372386932373]\n",
      "Epoch: [2][2/5]\n",
      "Train Loss: [loss.val=0.7245501279830933] [loss.avg=0.7193111578623453]\n",
      "Train Batch Time: [0.16977659861246744]\n",
      "Epoch: [2][3/5]\n",
      "Train Loss: [loss.val=0.7166790962219238] [loss.avg=0.71865314245224]\n",
      "Train Batch Time: [0.1621454954147339]\n",
      "Epoch: [2][4/5]\n",
      "Train Loss: [loss.val=0.7146050333976746] [loss.avg=0.717843520641327]\n",
      "Train Batch Time: [0.15754060745239257]\n",
      "[0/5]\n",
      "Val Loss: [loss.val=236174.0] [loss.avg=236174.0]\n",
      "Val Batch Time: [0.14321637153625488]\n",
      "[1/5]\n",
      "Val Loss: [loss.val=362402.78125] [loss.avg=299288.390625]\n",
      "Val Batch Time: [0.09116947650909424]\n",
      "[2/5]\n",
      "Val Loss: [loss.val=221862.09375] [loss.avg=273479.625]\n",
      "Val Batch Time: [0.07323845227559407]\n",
      "[3/5]\n",
      "Val Loss: [loss.val=158246.5] [loss.avg=244671.34375]\n",
      "Val Batch Time: [0.06449729204177856]\n",
      "[4/5]\n",
      "Val Loss: [loss.val=156541.765625] [loss.avg=227045.428125]\n",
      "Val Batch Time: [0.05914449691772461]\n",
      "Epoch: [3][0/5]\n",
      "Train Loss: [loss.val=0.7006610631942749] [loss.avg=0.7006610631942749]\n",
      "Train Batch Time: [0.2281644344329834]\n",
      "Epoch: [3][1/5]\n",
      "Train Loss: [loss.val=0.6966626048088074] [loss.avg=0.6986618340015411]\n",
      "Train Batch Time: [0.1836566925048828]\n",
      "Epoch: [3][2/5]\n",
      "Train Loss: [loss.val=0.7070506811141968] [loss.avg=0.7014581163724264]\n",
      "Train Batch Time: [0.1690096060434977]\n",
      "Epoch: [3][3/5]\n",
      "Train Loss: [loss.val=0.7132721543312073] [loss.avg=0.7044116258621216]\n",
      "Train Batch Time: [0.16135019063949585]\n",
      "Epoch: [3][4/5]\n",
      "Train Loss: [loss.val=0.718158483505249] [loss.avg=0.7071609973907471]\n",
      "Train Batch Time: [0.15705451965332032]\n",
      "[0/5]\n",
      "Val Loss: [loss.val=905.5560302734375] [loss.avg=905.5560302734375]\n",
      "Val Batch Time: [0.1358778476715088]\n",
      "[1/5]\n",
      "Val Loss: [loss.val=1054.8673095703125] [loss.avg=980.211669921875]\n",
      "Val Batch Time: [0.08782064914703369]\n",
      "[2/5]\n",
      "Val Loss: [loss.val=1352.239990234375] [loss.avg=1104.2211100260417]\n",
      "Val Batch Time: [0.07140874862670898]\n",
      "[3/5]\n",
      "Val Loss: [loss.val=1462.0057373046875] [loss.avg=1193.6672668457031]\n",
      "Val Batch Time: [0.06299799680709839]\n",
      "[4/5]\n",
      "Val Loss: [loss.val=1045.0340576171875] [loss.avg=1163.940625]\n",
      "Val Batch Time: [0.057943105697631836]\n",
      "Epoch: [4][0/5]\n",
      "Train Loss: [loss.val=0.6542873978614807] [loss.avg=0.6542873978614807]\n",
      "Train Batch Time: [0.24145245552062988]\n",
      "Epoch: [4][1/5]\n",
      "Train Loss: [loss.val=0.6979957222938538] [loss.avg=0.6761415600776672]\n",
      "Train Batch Time: [0.1902071237564087]\n",
      "Epoch: [4][2/5]\n",
      "Train Loss: [loss.val=0.7048487663269043] [loss.avg=0.685710628827413]\n",
      "Train Batch Time: [0.17321077982584634]\n",
      "Epoch: [4][3/5]\n",
      "Train Loss: [loss.val=0.7087564468383789] [loss.avg=0.6914720833301544]\n",
      "Train Batch Time: [0.16517126560211182]\n",
      "Epoch: [4][4/5]\n",
      "Train Loss: [loss.val=0.6899170279502869] [loss.avg=0.6911610722541809]\n",
      "Train Batch Time: [0.1594414234161377]\n",
      "[0/5]\n",
      "Val Loss: [loss.val=63.802207946777344] [loss.avg=63.802207946777344]\n",
      "Val Batch Time: [0.14114785194396973]\n",
      "[1/5]\n",
      "Val Loss: [loss.val=110.86296081542969] [loss.avg=87.33258438110352]\n",
      "Val Batch Time: [0.09006214141845703]\n",
      "[2/5]\n",
      "Val Loss: [loss.val=65.37364196777344] [loss.avg=80.01293690999348]\n",
      "Val Batch Time: [0.07270026206970215]\n",
      "[3/5]\n",
      "Val Loss: [loss.val=151.03591918945312] [loss.avg=97.7686824798584]\n",
      "Val Batch Time: [0.06391638517379761]\n",
      "[4/5]\n",
      "Val Loss: [loss.val=98.28421020507812] [loss.avg=97.87178802490234]\n",
      "Val Batch Time: [0.05863323211669922]\n",
      "New best model by [Val Loss = 97.87178802490234]\n",
      "Saving model checkpoint\n",
      "Epoch: [5][0/5]\n",
      "Train Loss: [loss.val=0.6978315711021423] [loss.avg=0.6978315711021423]\n",
      "Train Batch Time: [0.22951221466064453]\n",
      "Epoch: [5][1/5]\n",
      "Train Loss: [loss.val=0.6498614549636841] [loss.avg=0.6738465130329132]\n",
      "Train Batch Time: [0.18442857265472412]\n",
      "Epoch: [5][2/5]\n",
      "Train Loss: [loss.val=0.6942920088768005] [loss.avg=0.680661678314209]\n",
      "Train Batch Time: [0.16913859049479166]\n",
      "Epoch: [5][3/5]\n",
      "Train Loss: [loss.val=0.6836316585540771] [loss.avg=0.681404173374176]\n",
      "Train Batch Time: [0.16165447235107422]\n",
      "Epoch: [5][4/5]\n",
      "Train Loss: [loss.val=0.6955384612083435] [loss.avg=0.6842310309410096]\n",
      "Train Batch Time: [0.15720653533935547]\n",
      "[0/5]\n",
      "Val Loss: [loss.val=30.384653091430664] [loss.avg=30.384653091430664]\n",
      "Val Batch Time: [0.14316797256469727]\n",
      "[1/5]\n",
      "Val Loss: [loss.val=16.718952178955078] [loss.avg=23.55180263519287]\n",
      "Val Batch Time: [0.0908883810043335]\n",
      "[2/5]\n",
      "Val Loss: [loss.val=12.490323066711426] [loss.avg=19.86464277903239]\n",
      "Val Batch Time: [0.07301958401997884]\n",
      "[3/5]\n",
      "Val Loss: [loss.val=15.350114822387695] [loss.avg=18.736010789871216]\n",
      "Val Batch Time: [0.06406289339065552]\n",
      "[4/5]\n",
      "Val Loss: [loss.val=24.630090713500977] [loss.avg=19.914826774597167]\n",
      "Val Batch Time: [0.058968973159790036]\n",
      "New best model by [Val Loss = 19.914826774597167]\n",
      "Saving model checkpoint\n",
      "Epoch: [6][0/5]\n",
      "Train Loss: [loss.val=0.6956853270530701] [loss.avg=0.6956853270530701]\n",
      "Train Batch Time: [0.23767757415771484]\n",
      "Epoch: [6][1/5]\n",
      "Train Loss: [loss.val=0.695887565612793] [loss.avg=0.6957864463329315]\n",
      "Train Batch Time: [0.1884007453918457]\n",
      "Epoch: [6][2/5]\n",
      "Train Loss: [loss.val=0.6791955232620239] [loss.avg=0.690256138642629]\n",
      "Train Batch Time: [0.17213861147562662]\n",
      "Epoch: [6][3/5]\n",
      "Train Loss: [loss.val=0.6897075772285461] [loss.avg=0.6901189982891083]\n",
      "Train Batch Time: [0.16418927907943726]\n",
      "Epoch: [6][4/5]\n",
      "Train Loss: [loss.val=0.6754801273345947] [loss.avg=0.6871912240982055]\n",
      "Train Batch Time: [0.1594315528869629]\n",
      "[0/5]\n",
      "Val Loss: [loss.val=7.631121635437012] [loss.avg=7.631121635437012]\n",
      "Val Batch Time: [0.14249467849731445]\n",
      "[1/5]\n",
      "Val Loss: [loss.val=5.255445957183838] [loss.avg=6.443283796310425]\n",
      "Val Batch Time: [0.09063386917114258]\n",
      "[2/5]\n",
      "Val Loss: [loss.val=5.295742034912109] [loss.avg=6.060769875844319]\n",
      "Val Batch Time: [0.07279690106709798]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[3/5]\n",
      "Val Loss: [loss.val=0.6886870265007019] [loss.avg=4.717749163508415]\n",
      "Val Batch Time: [0.06417089700698853]\n",
      "[4/5]\n",
      "Val Loss: [loss.val=4.316972732543945] [loss.avg=4.637593877315521]\n",
      "Val Batch Time: [0.05886058807373047]\n",
      "New best model by [Val Loss = 4.637593877315521]\n",
      "Saving model checkpoint\n",
      "Epoch: [7][0/5]\n",
      "Train Loss: [loss.val=0.679855465888977] [loss.avg=0.679855465888977]\n",
      "Train Batch Time: [0.23217296600341797]\n",
      "Epoch: [7][1/5]\n",
      "Train Loss: [loss.val=0.6917006969451904] [loss.avg=0.6857780814170837]\n",
      "Train Batch Time: [0.18575525283813477]\n",
      "Epoch: [7][2/5]\n",
      "Train Loss: [loss.val=0.6824129819869995] [loss.avg=0.6846563816070557]\n",
      "Train Batch Time: [0.1706267992655436]\n",
      "Epoch: [7][3/5]\n",
      "Train Loss: [loss.val=0.6869540214538574] [loss.avg=0.6852307915687561]\n",
      "Train Batch Time: [0.16267609596252441]\n",
      "Epoch: [7][4/5]\n",
      "Train Loss: [loss.val=0.6912040114402771] [loss.avg=0.6864254355430603]\n",
      "Train Batch Time: [0.15808477401733398]\n",
      "[0/5]\n",
      "Val Loss: [loss.val=0.7870739102363586] [loss.avg=0.7870739102363586]\n",
      "Val Batch Time: [0.13793635368347168]\n",
      "[1/5]\n",
      "Val Loss: [loss.val=1.6397342681884766] [loss.avg=1.2134040892124176]\n",
      "Val Batch Time: [0.08825993537902832]\n",
      "[2/5]\n",
      "Val Loss: [loss.val=2.328420639038086] [loss.avg=1.5850762724876404]\n",
      "Val Batch Time: [0.07123462359110515]\n",
      "[3/5]\n",
      "Val Loss: [loss.val=3.0136187076568604] [loss.avg=1.9422118812799454]\n",
      "Val Batch Time: [0.06266933679580688]\n",
      "[4/5]\n",
      "Val Loss: [loss.val=2.428877592086792] [loss.avg=2.0395450234413146]\n",
      "Val Batch Time: [0.05771150588989258]\n",
      "New best model by [Val Loss = 2.0395450234413146]\n",
      "Saving model checkpoint\n",
      "Epoch: [8][0/5]\n",
      "Train Loss: [loss.val=0.6858962774276733] [loss.avg=0.6858962774276733]\n",
      "Train Batch Time: [0.23398351669311523]\n",
      "Epoch: [8][1/5]\n",
      "Train Loss: [loss.val=0.6798851490020752] [loss.avg=0.6828907132148743]\n",
      "Train Batch Time: [0.1865178346633911]\n",
      "Epoch: [8][2/5]\n",
      "Train Loss: [loss.val=0.6841204762458801] [loss.avg=0.6833006342252096]\n",
      "Train Batch Time: [0.17065739631652832]\n",
      "Epoch: [8][3/5]\n",
      "Train Loss: [loss.val=0.6806289553642273] [loss.avg=0.682632714509964]\n",
      "Train Batch Time: [0.16276293992996216]\n",
      "Epoch: [8][4/5]\n",
      "Train Loss: [loss.val=0.6791672706604004] [loss.avg=0.6819396257400513]\n",
      "Train Batch Time: [0.15808873176574706]\n",
      "[0/5]\n",
      "Val Loss: [loss.val=1.750731110572815] [loss.avg=1.750731110572815]\n",
      "Val Batch Time: [0.13492441177368164]\n",
      "[1/5]\n",
      "Val Loss: [loss.val=1.3666560649871826] [loss.avg=1.5586935877799988]\n",
      "Val Batch Time: [0.08690524101257324]\n",
      "[2/5]\n",
      "Val Loss: [loss.val=0.7292246222496033] [loss.avg=1.2822039326032002]\n",
      "Val Batch Time: [0.07044347127278645]\n",
      "[3/5]\n",
      "Val Loss: [loss.val=0.6855949759483337] [loss.avg=1.1330516934394836]\n",
      "Val Batch Time: [0.0623210072517395]\n",
      "[4/5]\n",
      "Val Loss: [loss.val=0.949716329574585] [loss.avg=1.096384620666504]\n",
      "Val Batch Time: [0.05733003616333008]\n",
      "New best model by [Val Loss = 1.096384620666504]\n",
      "Saving model checkpoint\n",
      "Epoch: [9][0/5]\n",
      "Train Loss: [loss.val=0.6825721859931946] [loss.avg=0.6825721859931946]\n",
      "Train Batch Time: [0.23108959197998047]\n",
      "Epoch: [9][1/5]\n",
      "Train Loss: [loss.val=0.6676246523857117] [loss.avg=0.6750984191894531]\n",
      "Train Batch Time: [0.1846069097518921]\n",
      "Epoch: [9][2/5]\n",
      "Train Loss: [loss.val=0.6787876486778259] [loss.avg=0.676328162352244]\n",
      "Train Batch Time: [0.16964960098266602]\n",
      "Epoch: [9][3/5]\n",
      "Train Loss: [loss.val=0.6922106146812439] [loss.avg=0.680298775434494]\n",
      "Train Batch Time: [0.16210293769836426]\n",
      "Epoch: [9][4/5]\n",
      "Train Loss: [loss.val=0.6926572322845459] [loss.avg=0.6827704668045044]\n",
      "Train Batch Time: [0.1576221466064453]\n",
      "[0/5]\n",
      "Val Loss: [loss.val=0.6892205476760864] [loss.avg=0.6892205476760864]\n",
      "Val Batch Time: [0.14147067070007324]\n",
      "[1/5]\n",
      "Val Loss: [loss.val=0.5865424275398254] [loss.avg=0.6378814876079559]\n",
      "Val Batch Time: [0.0902400016784668]\n",
      "[2/5]\n",
      "Val Loss: [loss.val=0.6757014989852905] [loss.avg=0.6504881580670675]\n",
      "Val Batch Time: [0.07266751925150554]\n",
      "[3/5]\n",
      "Val Loss: [loss.val=0.6820718050003052] [loss.avg=0.6583840698003769]\n",
      "Val Batch Time: [0.06378394365310669]\n",
      "[4/5]\n",
      "Val Loss: [loss.val=1.2962669134140015] [loss.avg=0.7859606385231018]\n",
      "Val Batch Time: [0.05849223136901856]\n",
      "New best model by [Val Loss = 0.7859606385231018]\n",
      "Saving model checkpoint\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_data = {}\n",
    "plot_data['train_loss'] = zeros(EPOCHS)\n",
    "plot_data['val_loss'] = zeros(EPOCHS)\n",
    "plot_data['epoch'] = 0\n",
    "\n",
    "it_axes = arange(EPOCHS)\n",
    "_, ax1 = subplots()\n",
    "ax2 = ax1.twinx()\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax1.set_ylabel('Train Loss (r), Val Loss (y)')\n",
    "ax1.set_ylim([0, 2])\n",
    "best_loss = 1000\n",
    "\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    plot_data['epoch'] = epoch\n",
    "    # train for one epoch\n",
    "    plot_data = train(train_loader, model, criterion, optimizer, epoch, print_freq, plot_data, GPU)\n",
    "    # evaluate on validation set\n",
    "    plot_data = validate(val_loader, model, criterion, print_freq, plot_data, GPU)\n",
    "    \n",
    "    # remember best model and save checkpoint\n",
    "    is_best = plot_data['val_loss'][epoch] < best_loss\n",
    "    if is_best:\n",
    "        val_loss = plot_data['val_loss'][epoch]\n",
    "        logger.info(f'New best model by [Val Loss = {val_loss}]')\n",
    "        best_loss = plot_data['val_loss'][epoch]\n",
    "        filename = f'{DATASET_ROOT}/models/multi-modal-epoch-{epoch}'\n",
    "        save_checkpoint(model, filename)\n",
    "    \n",
    "    ax1.plot(it_axes[0: epoch+1], plot_data['train_loss'][0: epoch+1], 'r')\n",
    "    ax1.plot(it_axes[0: epoch+1], plot_data['val_loss'][0: epoch+1], 'y')\n",
    "    plt.grid(True)\n",
    "    plt.title('Multi-Modal CNN')\n",
    "    \n",
    "    # save plot to disk\n",
    "    title = f'{DATASET_ROOT}plots/epoch_{epoch}.jpg'\n",
    "    savefig(title, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0cb409",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
