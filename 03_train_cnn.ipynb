{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "268a5683",
   "metadata": {},
   "source": [
    "#### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "306cf552",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'logger'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-88c41eee51fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'logger'"
     ]
    }
   ],
   "source": [
    "from pylab import zeros, arange, subplots, plt, savefig\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision.models as models\n",
    "from collections import OrderedDict\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import logging\n",
    "import torch\n",
    "import math\n",
    "import time\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "facf9962",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    def __init__(self, root_dir, split, embedding_dimensionality):\n",
    "        self.root_dir = root_dir\n",
    "        self.split = split\n",
    "        self.embedding_dimensionality = embedding_dimensionality\n",
    "        self.preprocess = transforms.Compose([transforms.RandomHorizontalFlip(), \n",
    "                                              transforms.RandomCrop(224), \n",
    "                                              transforms.ToTensor(), \n",
    "                                              transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                                                                   std=[0.229, 0.224, 0.225])\n",
    "                                             ])\n",
    "\n",
    "        print(f'Loading data from {split}')\n",
    "        gt_file = root_dir + split\n",
    "        \n",
    "        # count number of images in the split\n",
    "        num_lines = 0\n",
    "        with open(gt_file, 'r') as f:\n",
    "            for i, l in enumerate(f):\n",
    "                pass\n",
    "        num_lines = i + 1\n",
    "\n",
    "        # Load img IDs and caption embeddings to memory\n",
    "        print(\"Num lines: \" + str(num_lines))\n",
    "        self.img_ids = np.empty([num_lines], dtype=\"S50\")\n",
    "        self.captions_embeddings = np.zeros((num_lines, self.embedding_dimensionality), dtype=np.float32)\n",
    "        print(\"Loading labels ...\")\n",
    "        with open(gt_file, 'r') as annsfile:\n",
    "            for c, i in enumerate(annsfile):\n",
    "                if c == num_lines: \n",
    "                    break\n",
    "                id_, vec = i.split('\\t')\n",
    "                vec = vec.strip().split(',')\n",
    "                self.img_ids[c] = id_\n",
    "                # Load caption word2vec embedding\n",
    "                for l in range(0, self.embedding_dimensionality):\n",
    "                    self.captions_embeddings[c, l] = float(vec[l])\n",
    "\n",
    "        print(\"Data read.\")\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.img_ids[idx].decode('utf-8')\n",
    "        input_img = Image.open(self.root_dir + 'images/newyork/' + img_name + '.jpg').convert('RGB')\n",
    "        img_tensor = self.preprocess(input_img)\n",
    "        target_tensor = torch.from_numpy(self.captions_embeddings[idx, :])\n",
    "        return img_name, img_tensor, target_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd13a26b",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9febbcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, embedding_dimensionality):\n",
    "        super(Model, self).__init__()\n",
    "        self.cnn = models.resnet50(pretrained=True, num_classes=embedding_dimensionality)\n",
    "\n",
    "    def forward(self, image):\n",
    "        x = self.cnn(image)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "838e7b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9c8af0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch, print_freq, plot_data, gpu):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    loss_meter = AverageMeter()\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (img_name, image, target) in enumerate(train_loader):\n",
    "        target_var = torch.autograd.Variable(target).cuda(gpu)\n",
    "        image_var = torch.autograd.Variable(image)\n",
    "\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        # compute output\n",
    "        output = model(image_var)\n",
    "        loss = criterion(output, target_var)\n",
    "\n",
    "        # measure and record loss\n",
    "        loss_meter.update(loss.data.item(), image.size()[0])\n",
    "      \n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % print_freq == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.8f} ({loss.avg:.8f})\\t'.format(\n",
    "                   epoch, i, len(train_loader), batch_time=batch_time,\n",
    "                   data_time=data_time, loss=loss_meter))\n",
    "\n",
    "    plot_data['train_loss'][plot_data['epoch']] = loss_meter.avg\n",
    "\n",
    "    return plot_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae160e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion, print_freq, plot_data, gpu):\n",
    "    with torch.no_grad():\n",
    "\n",
    "        batch_time = AverageMeter()\n",
    "        loss_meter = AverageMeter()\n",
    "\n",
    "        # switch to evaluate mode\n",
    "        model.eval()\n",
    "\n",
    "        end = time.time()\n",
    "        for i, (img_name, image, target) in enumerate(val_loader):\n",
    "            target_var = torch.autograd.Variable(target).cuda(gpu)\n",
    "            image_var = torch.autograd.Variable(image)\n",
    "\n",
    "            # compute output\n",
    "            output = model(image_var)\n",
    "            loss = criterion(output, target_var)\n",
    "\n",
    "            # measure and record loss\n",
    "            loss_meter.update(loss.data.item(), image.size()[0])\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % print_freq == 0:\n",
    "                print('Test: [{0}/{1}]\\t'\n",
    "                          'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                      'Loss {loss.val:.8f} ({loss.avg:.8f})\\t'.format(\n",
    "                       i, len(val_loader), batch_time=batch_time, loss=loss_meter))\n",
    "\n",
    "        plot_data['val_loss'][plot_data['epoch']] = loss_meter.avg\n",
    "\n",
    "    return plot_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f528d36",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d20268a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_id = 'multi-modal'\n",
    "dataset_root = './data/'\n",
    "split_train = 'embedding/caption_embedding.csv'\n",
    "split_val = 'embedding/caption_embedding.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b29417a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dimensionality = 1000  # Number of CNN outputs (dimensionality of the word2vec model)\n",
    "batch_size = 64 # Set as large as possible\n",
    "epochs = 10 # Converges around y\n",
    "print_freq = 1 # How frequently print loss in screen\n",
    "plot = True  # Save a plot with the training and validation losses\n",
    "workers = 64 # Num of data loading workers\n",
    "gpu = 0\n",
    "lr = 0.01 # 0.01 Is a good start\n",
    "momentum = 0.9\n",
    "weight_decay = 1e-4\n",
    "\n",
    "# Set model and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss().cuda(gpu) # Sigmoid + Cross Entropy Loss \n",
    "\n",
    "# Create ResNet50 model with custom number of outputs\n",
    "model = Model(embedding_dimensionality=embedding_dimensionality).cuda(gpu)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr) # ADAM optimizer\n",
    "model = torch.nn.DataParallel(model, device_ids=[gpu])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ffa58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cudnn.benchmark = True\n",
    "\n",
    "# Data loading code (pin_memory allows better transferring of samples to GPU memory)\n",
    "train_dataset = Dataset(dataset_root, split_train, embedding_dimensionality)\n",
    "val_dataset = Dataset(dataset_root, split_val, embedding_dimensionality)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True, \n",
    "                                           num_workers=workers, \n",
    "                                           pin_memory=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, \n",
    "                                         batch_size=batch_size, \n",
    "                                         shuffle=True, \n",
    "                                         num_workers=workers, \n",
    "                                         pin_memory=True)\n",
    "\n",
    "\n",
    "# Plotting is not needed if we don't want to monitor training\n",
    "# Also, standard monitoring tools such as Visom or Tensorflow could be used.\n",
    "# Plotting config\n",
    "plot_data = {}\n",
    "plot_data['train_loss'] = zeros(epochs)\n",
    "plot_data['val_loss'] = zeros(epochs)\n",
    "plot_data['epoch'] = 0\n",
    "it_axes = arange(epochs)\n",
    "_, ax1 = subplots()\n",
    "ax2 = ax1.twinx()\n",
    "ax1.set_xlabel('epochs')\n",
    "ax1.set_ylabel('train loss (r), val loss (y)')\n",
    "ax1.set_ylim([0, 2])\n",
    "best_loss = 1000\n",
    "\n",
    "\n",
    "print(\"Dataset and model ready. Starting training ...\")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    plot_data['epoch'] = epoch\n",
    "    # Train for one epoch\n",
    "    plot_data = train(train_loader, model, criterion, optimizer, epoch, print_freq, plot_data, gpu)\n",
    "    # Evaluate on validation set\n",
    "    plot_data = validate(val_loader, model, criterion, print_freq, plot_data, gpu)\n",
    "    \n",
    "    print(plot_data)\n",
    "\n",
    "\n",
    "    if plot:\n",
    "\n",
    "        ax1.plot(it_axes[0:epoch+1], plot_data['train_loss'][0:epoch+1], 'r')\n",
    "        ax1.plot(it_axes[0:epoch+1], plot_data['val_loss'][0:epoch+1], 'y')\n",
    "        plt.grid(True)\n",
    "        plt.title(training_id)\n",
    "\n",
    "        # Save graph to disk\n",
    "        if epoch % 1 == 0 and epoch != 0:\n",
    "            title = dataset_root +'training/' + training_id + '_epoch_' + str(epoch) + '.png'\n",
    "            savefig(title, bbox_inches='tight')\n",
    "\n",
    "print(\"Training completed for \" + str(epochs) + \" epochs.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f473f8b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ab6b37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc2e8d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e96446",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8dd5061",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bedc3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0072a0c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac03af69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62bf571",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f14bb7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
